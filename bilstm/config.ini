[Model]
embedding_dim = 64 ; Dimension of embedding layer
hidden_dim = 64 ; BiLSTM hidden state dimensionality
num_layers = 2 ; How many BiLSTMs to stack on top of another

[Training]
lr = 1e-3
number_epochs = 100

[Data]
batch_size = 8
data_folder = "data/sponsor_nlp_data"
model_store_path = "data/models/"
model_name = "bilstm2"
model_vocab_store = "data/model_metadata/vocab"
config_store = "data/model_metadata/configs"
progress_store = "data/model_metadata/training_progress"