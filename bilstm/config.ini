[Model]
gru = True ; If true, use GRU instead of LSTM
embedding_dim = 64 ; Dimension of embedding layer
hidden_dim = 64 ; BiLSTM hidden state dimensionality
num_layers = 2 ; How many BiLSTMs to stack on top of another

[Training]
lr = 1e-3
number_epochs = 100

[Data]
batch_size = 8
data_folder = "data/sponsor_nlp_data"
model_store_path = "data/models/"
model_name = "bigru2"
model_vocab_store = "data/model_metadata/vocab"
config_store = "data/model_metadata/configs"
progress_store = "data/model_metadata/training_progress"

[Frontend]
template_location = "frontend/templates/inference_template.html"
css_location = "frontend/templates/inference_template.css"
results_location = "frontend/results"